# -*- coding: utf-8 -*-
"""fraud_detection_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1af9IeEa5WiEB4On7GOAb1Dunhwqt-7ar
"""

!pip install -q kagglehub
import kagglehub

# Download latest version
path = kagglehub.dataset_download("rupakroy/online-payments-fraud-detection-dataset")

print("Path to dataset files:", path)

"""# Task
Build a Streamlit application for online payments fraud detection. The application should load and preprocess the dataset from the path specified by the `path` variable, train a fraud detection model, and then allow users to input transaction details to predict if a transaction is fraudulent. Finally, summarize the application's functionality and provide instructions on how to run it.

## Load and Prepare Data

### Subtask:
Load the dataset from the provided path, perform necessary data cleaning, handle missing values, and encode categorical features to prepare the data for model training.

**Reasoning**:
First, I will import the pandas library to enable data manipulation and analysis.
"""

import pandas as pd

print("pandas library imported.")

"""**Reasoning**:
Now, I will construct the full path to the dataset file using the `path` variable and `os.path.join` to ensure correct file access across different operating systems. This `path` variable contains the directory where the dataset was downloaded.


"""

import os

file_path = os.path.join(path, "PS_20174392719_1491204439457_log.csv")
print(f"Constructed file path: {file_path}")

"""**Reasoning**:
I will load the dataset from the constructed `file_path` into a pandas DataFrame and then display the first few rows to inspect its structure and content, as per the instructions.


"""

df = pd.read_csv(file_path)
print("Dataset loaded successfully.")
print("First 5 rows of the DataFrame:")
print(df.head())

"""**Reasoning**:
To identify potential issues such as missing values or incorrect data types, I will inspect the DataFrame's information including data types and non-null counts for each column.


"""

print("DataFrame Info:")
df.info()

"""**Reasoning**:
I will display descriptive statistics of the numerical columns to understand their distribution, central tendency, and dispersion, which can highlight potential outliers or data entry errors.


"""

print("Descriptive statistics for numerical columns:")
print(df.describe())

"""**Reasoning**:
Following the instructions, I will drop the specified columns ('nameOrig', 'nameDest', and 'isFlaggedFraud') from the DataFrame as they are not considered useful for fraud prediction.


"""

df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)
print("Dropped 'nameOrig', 'nameDest', and 'isFlaggedFraud' columns.")
print("Updated DataFrame columns:")
print(df.columns)

"""**Reasoning**:
To prepare the categorical 'type' column for model training, I will convert it into a numerical format using one-hot encoding.


"""

df = pd.get_dummies(df, columns=['type'], drop_first=True)
print("One-hot encoding applied to 'type' column.")
print("First 5 rows of the updated DataFrame:")
print(df.head())

"""**Reasoning**:
As instructed, I will separate the features (X) from the target variable (y). The 'isFraud' column will be assigned to y, and all remaining columns will be assigned to X to prepare the data for model training.


"""

X = df.drop('isFraud', axis=1)
y = df['isFraud']

print("Features (X) and target variable (y) separated.")
print(f"Shape of X: {X.shape}")
print(f"Shape of y: {y.shape}")

"""## Train Fraud Detection Model

### Subtask:
Split the preprocessed data into training and testing sets, then train a suitable machine learning model to predict fraud. Evaluate the model's performance.

**Reasoning**:
The first step in training the model is to split the data into training and testing sets. I will import `train_test_split` from `sklearn.model_selection` as instructed.
"""

from sklearn.model_selection import train_test_split

print("train_test_split imported.")

"""**Reasoning**:
Now that `train_test_split` is imported, I will split the features `X` and target `y` into training and testing sets with a 20% test size, a random state of 42 for reproducibility, and stratify by `y` to maintain the proportion of fraud cases.


"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Data split into training and testing sets.")
print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_test: {y_test.shape}")

"""**Reasoning**:
Following the instructions, I will now import the `LogisticRegression` model from `sklearn.linear_model` to prepare for training the fraud detection model.


"""

from sklearn.linear_model import LogisticRegression

print("LogisticRegression imported.")

"""**Reasoning**:
As instructed, I will initialize a `LogisticRegression` model, setting `solver='liblinear'` and `random_state=42` to ensure reproducibility and handle potential convergence issues with large datasets.


"""

model = LogisticRegression(solver='liblinear', random_state=42)
print("LogisticRegression model initialized.")

"""**Reasoning**:
Now that the `LogisticRegression` model is initialized, I will train it using the `X_train` and `y_train` datasets as instructed. This step will fit the model to the training data, allowing it to learn the patterns for fraud detection.


"""

model.fit(X_train, y_train)
print("LogisticRegression model trained on the training data.")

"""**Reasoning**:
The previous step resulted in a `ConvergenceWarning` indicating that the `liblinear` solver failed to converge. To address this, I will re-initialize the `LogisticRegression` model with an increased `max_iter` value, as suggested by the warning, and then retrain it.


"""

model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)
print("LogisticRegression model re-initialized with increased max_iter.")

"""**Reasoning**:
Now that the `LogisticRegression` model has been re-initialized with an increased `max_iter`, I will retrain it using the `X_train` and `y_train` datasets to address the previous convergence warning and fit the model to the training data.


"""

model.fit(X_train, y_train)
print("LogisticRegression model retrained with increased max_iter.")

"""**Reasoning**:
As instructed, I will import `classification_report` and `accuracy_score` from `sklearn.metrics` to evaluate the performance of the trained Logistic Regression model.


"""

from sklearn.metrics import classification_report, accuracy_score

print("classification_report and accuracy_score imported.")

"""**Reasoning**:
Now that the model is trained and evaluation metrics are imported, I will use the trained model to make predictions on the test set (`X_test`) as instructed.


"""

y_pred = model.predict(X_test)
print("Predictions made on the test set.")

"""**Reasoning**:
Now that predictions have been made, I will print the classification report and accuracy score to evaluate the model's performance on the test set, as instructed.


"""

print("Classification Report:")
print(classification_report(y_test, y_pred))
print(f"Accuracy Score: {accuracy_score(y_test, y_pred):.4f}")

"""## Build Streamlit Application

### Subtask:
Develop a Streamlit application that allows users to input transaction details, uses the trained model to predict whether the transaction is fraudulent, and displays the prediction result. The app should load the trained model and preprocess user inputs in the same way the training data was handled.

**Reasoning**:
As instructed, I will import the `joblib` library, which is used for efficiently saving and loading Python objects, including trained machine learning models, to disk.
"""

import joblib

print("joblib imported.")

"""**Reasoning**:
Following the instructions, I will save the trained `model` to a file named 'logistic_regression_model.joblib' using `joblib.dump()` so it can be loaded later by the Streamlit application.


"""

joblib.dump(model, 'logistic_regression_model.joblib')
print("Model saved as 'logistic_regression_model.joblib'")

"""**Reasoning**:
As instructed, I will save the feature column names (`X.columns`) to a file named 'model_columns.joblib' using `joblib.dump()`. This file will be crucial for the Streamlit app to ensure that new predictions use the features in the same order as the trained model.


"""

joblib.dump(X.columns, 'model_columns.joblib')
print("Feature columns saved as 'model_columns.joblib'")

"""**Reasoning**:
As instructed, I will create a new Python file named `fraud_detection_app.py` in the current directory. This file will contain the Streamlit application code for fraud detection.


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile fraud_detection_app.py
# 
# import streamlit as st
# import pandas as pd
# import joblib
# import numpy as np
# 
# # Load the trained model and feature columns
# model = joblib.load('logistic_regression_model.joblib')
# model_columns = joblib.load('model_columns.joblib')
# 
# st.title('Online Payments Fraud Detection App')
# st.write('Enter transaction details to predict if it is fraudulent.')
# 
# # Input widgets for numerical features
# step = st.slider('Step (Time step of the transaction)', 1, 743, 1)
# amount = st.number_input('Amount', min_value=0.0, value=1000.0, format="%.2f")
# oldbalanceOrg = st.number_input('Old Balance (Originator)', min_value=0.0, value=10000.0, format="%.2f")
# newbalanceOrig = st.number_input('New Balance (Originator)', min_value=0.0, value=9000.0, format="%.2f")
# oldbalanceDest = st.number_input('Old Balance (Destination)', min_value=0.0, value=5000.0, format="%.2f")
# newbalanceDest = st.number_input('New Balance (Destination)', min_value=0.0, value=5500.0, format="%.2f")
# 
# # Input widget for categorical 'type' feature
# transaction_type = st.selectbox(
#     'Transaction Type',
#     ('PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN')
# )
# 
# # Create a dictionary from user inputs
# input_data = {
#     'step': step,
#     'amount': amount,
#     'oldbalanceOrg': oldbalanceOrg,
#     'newbalanceOrig': newbalanceOrig,
#     'oldbalanceDest': oldbalanceDest,
#     'newbalanceDest': newbalanceDest,
# }
# 
# # Handle one-hot encoding for 'type' feature
# # Initialize all type columns to False
# for col in ['type_CASH_OUT', 'type_DEBIT', 'type_PAYMENT', 'type_TRANSFER']:
#     input_data[col] = False
# 
# # Set the selected transaction type to True
# if transaction_type == 'CASH_OUT':
#     input_data['type_CASH_OUT'] = True
# elif transaction_type == 'DEBIT':
#     input_data['type_DEBIT'] = True
# elif transaction_type == 'PAYMENT':
#     input_data['type_PAYMENT'] = True
# elif transaction_type == 'TRANSFER':
#     input_data['type_TRANSFER'] = True
# 
# # Convert input data to DataFrame, ensuring column order and types match training data
# input_df = pd.DataFrame([input_data])
# 
# # Reorder columns to match the model's training features
# # Filter model_columns to exclude 'isFraud' if it's there (it shouldn't be for X)
# expected_columns = [col for col in model_columns if col != 'isFraud']
# 
# # Add missing columns with default (False for boolean, 0 for numeric if any missing in X after one-hot)
# for col in expected_columns:
#     if col not in input_df.columns:
#         if 'type_' in col:
#             input_df[col] = False
#         else:
#             input_df[col] = 0.0 # Or appropriate default
# 
# input_df = input_df[expected_columns]
# 
# 
# # Make prediction when button is clicked
# if st.button('Predict Fraud'):
#     prediction = model.predict(input_df)
#     prediction_proba = model.predict_proba(input_df)
# 
#     st.write(f"### Prediction Result:")
#     if prediction[0] == 1:
#         st.error(f"Transaction is FRAUDULENT! (Probability: {prediction_proba[0][1]:.4f})")
#     else:
#         st.success(f"Transaction is NOT FRAUDULENT. (Probability: {prediction_proba[0][0]:.4f})")
#

"""## Final Task

### Subtask:
Provide a summary of the Streamlit application created, its functionality, and how to run it.

## Summary:

### Q&A
The Streamlit application created is an online payments fraud detection tool. It allows users to input various transaction details, such as step, amount, old and new balances for originator and destination accounts, and the transaction type. The application then uses a pre-trained Logistic Regression model to predict whether the transaction is fraudulent or not, displaying the prediction result and its associated probability.

To run the application:
1.  Ensure you have Python installed and Streamlit, pandas, scikit-learn, and joblib libraries are installed (`pip install streamlit pandas scikit-learn joblib`).
2.  Save the provided Streamlit application code as `fraud_detection_app.py`.
3.  Ensure the `logistic_regression_model.joblib` and `model_columns.joblib` files (generated during the model training and saving steps) are in the same directory as `fraud_detection_app.py`.
4.  Open a terminal or command prompt, navigate to the directory where you saved the files, and run the command: `streamlit run fraud_detection_app.py`.
5.  The application will open in your web browser.

### Data Analysis Key Findings
*   The initial dataset contained 6,362,620 transactions with 11 columns, including transaction details and fraud indicators.
*   No missing values were found in the dataset, simplifying the cleaning process.
*   Irrelevant columns (`nameOrig`, `nameDest`, `isFlaggedFraud`) were dropped, reducing the feature set.
*   The categorical `type` column was successfully one-hot encoded, generating new columns like `type_CASH_OUT`, `type_DEBIT`, `type_PAYMENT`, and `type_TRANSFER`.
*   A Logistic Regression model was trained for fraud detection. An initial convergence warning was resolved by increasing the `max_iter` parameter to 1000.
*   The trained model achieved a high overall accuracy of 0.9983 on the test set.
*   For the minority fraud class (class 1), the model showed a precision of 0.37 and a recall of 0.44, indicating challenges in accurately identifying all fraudulent transactions without a significant number of false positives.
*   The trained model and the feature column names were successfully serialized and saved using `joblib` for deployment in the Streamlit application.
*   The Streamlit application `fraud_detection_app.py` was developed to take user inputs for transaction details, preprocess them consistently with the training data, and use the loaded model to predict fraud.

### Insights or Next Steps
*   **Improve Fraud Detection for Minority Class**: Given the relatively low precision (0.37) and recall (0.44) for the fraud class, further model tuning, exploring different algorithms (e.g., Tree-based models like XGBoost or LightGBM), or using advanced techniques for imbalanced datasets (e.g., SMOTE, class weighting) could significantly improve the detection of actual fraud while maintaining overall accuracy.
*   **Feature Engineering**: Investigating the creation of new features (e.g., transaction velocity, spending patterns, ratios of balances) could provide the model with more predictive power, especially for the nuanced detection of fraudulent activities.
"""